{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ALEXNET\n"
      ],
      "metadata": {
        "id": "OmBJG_CEK11y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5eYpRMSEReS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import SVHN\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_data_full = SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_data_full = SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "subset_indices_train = np.random.choice(len(train_data_full), int(len(train_data_full) * 0.25), replace=False)\n",
        "subset_indices_test = np.random.choice(len(test_data_full), int(len(test_data_full) * 0.25), replace=False)\n",
        "\n",
        "train_data = Subset(train_data_full, subset_indices_train)\n",
        "test_data = Subset(test_data_full, subset_indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tV4psMaEpRa",
        "outputId": "84d6f916-fc96-4549-dad9-fe41e7aeee04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:05<00:00, 30750634.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:03<00:00, 17985146.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "alexnet.classifier[6] = nn.Linear(4096, 10)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alexnet.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EViiRmSEpU-",
        "outputId": "5aba5d11-208b-4953-e3ab-d11767ddb745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(alexnet.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "xoIdTW7wEz3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    alexnet.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = alexnet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQLFRzi_E6AC",
        "outputId": "2cc0c32a-e7b5-4ee3-e416-cd87f71c8d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.261521296218713\n",
            "Epoch 2, Loss: 2.24397593175908\n",
            "Epoch 3, Loss: 2.2429388242316164\n",
            "Epoch 4, Loss: 2.2420737643690476\n",
            "Epoch 5, Loss: 2.2422098025212303\n",
            "Epoch 6, Loss: 2.242847868789779\n",
            "Epoch 7, Loss: 2.2420169459818133\n",
            "Epoch 8, Loss: 2.2418157099016036\n",
            "Epoch 9, Loss: 2.2414872164510267\n",
            "Epoch 10, Loss: 2.241534146697679\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = alexnet(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f'F1 Score of the network on the test images: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyvLjvjaI2aF",
        "outputId": "8c40ce56-06dd-4a98-d247-fce1df3e63ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of the network on the test images: 0.032613168724279835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LENET-5"
      ],
      "metadata": {
        "id": "kmxB_W1jLXwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import SVHN\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Ods88GIgK8-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "train_data_full = SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_data_full = SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "subset_indices_train = np.random.choice(len(train_data_full), int(len(train_data_full) * 0.25), replace=False)\n",
        "subset_indices_test = np.random.choice(len(test_data_full), int(len(test_data_full) * 0.25), replace=False)\n",
        "\n",
        "train_data = Subset(train_data_full, subset_indices_train)\n",
        "test_data = Subset(test_data_full, subset_indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KAsv7PSNW6J",
        "outputId": "92fdf25b-b210-434a-9186-4aa1c3284c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "lenet5 = LeNet5()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lenet5.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAhMO5UnLdNF",
        "outputId": "ebeebc3f-846e-4df8-d29a-cb9b28d16224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lenet5.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "sB-6Z7bgLjIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    lenet5.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = lenet5(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUv8gejrLmMI",
        "outputId": "5b26d1ee-2ee2-4bf4-a383-26fae044a1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.9149828187679996\n",
            "Epoch 2, Loss: 0.824924253628229\n",
            "Epoch 3, Loss: 0.5983392911920979\n",
            "Epoch 4, Loss: 0.5056512654346872\n",
            "Epoch 5, Loss: 0.44937985148994763\n",
            "Epoch 6, Loss: 0.40755868165750536\n",
            "Epoch 7, Loss: 0.3703799912323104\n",
            "Epoch 8, Loss: 0.3424770115300338\n",
            "Epoch 9, Loss: 0.3135394052917118\n",
            "Epoch 10, Loss: 0.29156724298664916\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet5.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = lenet5(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f'F1 Score of the network on the test images: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wWaY9YiMqvS",
        "outputId": "bebe6669-dcee-450d-b670-ebd90e4faa80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of the network on the test images: 0.8310482088966923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG-16"
      ],
      "metadata": {
        "id": "4IXJ5JjTNy7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import SVHN\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "z13hm2erNson"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_data_full = SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_data_full = SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "subset_indices_train = np.random.choice(len(train_data_full), int(len(train_data_full) * 0.25), replace=False)\n",
        "subset_indices_test = np.random.choice(len(test_data_full), int(len(test_data_full) * 0.25), replace=False)\n",
        "\n",
        "train_data = Subset(train_data_full, subset_indices_train)\n",
        "test_data = Subset(test_data_full, subset_indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-cLtcBYN31d",
        "outputId": "a1f0d929-04bd-44d1-e5f7-134c7652b01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "\n",
        "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 10)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj-5zPMPN55d",
        "outputId": "ec3c8933-94c4-4bcb-fc99-9062923b00b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "CXURD_uoN8tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    vgg16.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = vgg16(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfOBQ8TtOC3J",
        "outputId": "9b139bb6-ad08-4926-f749-e2c76b50b5b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.2589390088542385\n",
            "Epoch 2, Loss: 2.241546790637271\n",
            "Epoch 3, Loss: 2.240274546242093\n",
            "Epoch 4, Loss: 2.238152712427509\n",
            "Epoch 5, Loss: 2.2385414886641044\n",
            "Epoch 6, Loss: 2.2371705556207093\n",
            "Epoch 7, Loss: 2.2378054135340877\n",
            "Epoch 8, Loss: 2.2377621245425825\n",
            "Epoch 9, Loss: 2.2377665885455946\n",
            "Epoch 10, Loss: 2.2367700211456727\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = vgg16(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f'F1 Score of the network on the test images: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdJ0ktg7OE36",
        "outputId": "e64fec2b-ee53-428d-b8eb-ea800ebf5ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of the network on the test images: 0.06345053429170527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET-18"
      ],
      "metadata": {
        "id": "44WuCmt9aw_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import SVHN\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "xOP22nLrai63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_data_full = SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_data_full = SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "subset_indices_train = np.random.choice(len(train_data_full), int(len(train_data_full) * 0.25), replace=False)\n",
        "subset_indices_test = np.random.choice(len(test_data_full), int(len(test_data_full) * 0.25), replace=False)\n",
        "\n",
        "train_data = Subset(train_data_full, subset_indices_train)\n",
        "test_data = Subset(test_data_full, subset_indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx3w3JLXpltH",
        "outputId": "8cce77b1-9a50-43e6-f5ea-f14e9d7a4a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:04<00:00, 38281480.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:01<00:00, 40697949.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet18.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ax6gCETpt9J",
        "outputId": "9c9e92b2-052c-4ad3-f4f9-150b12df5a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 160MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet18.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "hYFkTzXGp1mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet18.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet18(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puc1HaDLqE-S",
        "outputId": "dc5e75fd-95d2-4f4d-8594-807c5b37f2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5688363812980851\n",
            "Epoch 2, Loss: 0.31835718557602655\n",
            "Epoch 3, Loss: 0.26322105901403575\n",
            "Epoch 4, Loss: 0.2261971045134306\n",
            "Epoch 5, Loss: 0.18965918688188074\n",
            "Epoch 6, Loss: 0.14422098126499727\n",
            "Epoch 7, Loss: 0.13094492931159482\n",
            "Epoch 8, Loss: 0.10170914818261333\n",
            "Epoch 9, Loss: 0.09002261170148314\n",
            "Epoch 10, Loss: 0.06585662400802633\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet18(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f'F1 Score of the network on the test images: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKqjlkyWqKoj",
        "outputId": "8b722a58-f390-42ea-f3e8-f74857e4f99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of the network on the test images: 0.929175055247549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET-50"
      ],
      "metadata": {
        "id": "SbDjo0Nyt3ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import SVHN\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "9Qjtyr-htmDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_data_full = SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_data_full = SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "subset_indices_train = np.random.choice(len(train_data_full), int(len(train_data_full) * 0.25), replace=False)\n",
        "subset_indices_test = np.random.choice(len(test_data_full), int(len(test_data_full) * 0.25), replace=False)\n",
        "\n",
        "train_data = Subset(train_data_full, subset_indices_train)\n",
        "test_data = Subset(test_data_full, subset_indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIkfVC1lt-FG",
        "outputId": "fef920bd-b742-4898-bc84-be1ca9d812b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "resnet50.fc = nn.Linear(resnet50.fc.in_features, 10)\n",
        "resnet50.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAH78eHkuAXO",
        "outputId": "dee0b036-89bc-4df0-f15d-a4465b0ed741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 89.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet50.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv2tadH2uFc3",
        "outputId": "36e10de7-abcd-44c8-92e6-c6049b641d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.1474949276982116\n",
            "Epoch 2, Loss: 0.12120436064217949\n",
            "Epoch 3, Loss: 0.11478619175568144\n",
            "Epoch 4, Loss: 0.0922393358373904\n",
            "Epoch 5, Loss: 0.10100435560270916\n",
            "Epoch 6, Loss: 0.07923400851680099\n",
            "Epoch 7, Loss: 0.06392961704929198\n",
            "Epoch 8, Loss: 0.054561494902649124\n",
            "Epoch 9, Loss: 0.05575717256180365\n",
            "Epoch 10, Loss: 0.06132298030194521\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet50(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f'F1 Score of the network on the test images: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmoOuIP7uKZR",
        "outputId": "325b9055-ff65-451e-b9c0-c5494d52bd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of the network on the test images: 0.9239145583115995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET-101"
      ],
      "metadata": {
        "id": "Zyw4YHke-_4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.datasets import SVHN\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "khcllT84-7d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_data_full = SVHN(root='./data', split='train', download=True, transform=transform)\n",
        "test_data_full = SVHN(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "subset_indices_train = np.random.choice(len(train_data_full), int(len(train_data_full) * 0.25), replace=False)\n",
        "subset_indices_test = np.random.choice(len(test_data_full), int(len(test_data_full) * 0.25), replace=False)\n",
        "\n",
        "train_data = Subset(train_data_full, subset_indices_train)\n",
        "test_data = Subset(test_data_full, subset_indices_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atIYQ61t_KbE",
        "outputId": "a5141dda-04c8-4526-bad4-f814d869190d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:04<00:00, 43839168.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:02<00:00, 32006079.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet101 = models.resnet101(pretrained=True)\n",
        "resnet101.fc = nn.Linear(resnet101.fc.in_features, 10)\n",
        "resnet101.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet101.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "0_fELQ20_N0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet101.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet101(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93rPOlSu_dLX",
        "outputId": "4cc6b806-8b54-45e4-ba13-7b5682f2d33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.2624169313470732\n",
            "Epoch 2, Loss: 2.233730837936801\n",
            "Epoch 3, Loss: 2.2319924146925176\n",
            "Epoch 4, Loss: 2.165173350620436\n",
            "Epoch 5, Loss: 1.3959651833325364\n",
            "Epoch 6, Loss: 0.5771276571675745\n",
            "Epoch 7, Loss: 0.4001978860215575\n",
            "Epoch 8, Loss: 0.33705174419086226\n",
            "Epoch 9, Loss: 0.30024609121170553\n",
            "Epoch 10, Loss: 0.263626370257186\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet101.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet101(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f'F1 Score of the network on the test images: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW1rZuoGGgxK",
        "outputId": "1b05ced6-d026-4990-9d87-b18d99c081bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of the network on the test images: 0.920626177590429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSYM2QZWFf7S",
        "outputId": "78ee6ad8-dbce-440d-8650-4dea925478d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "models = ['LeNet-5', 'AlexNet', 'VGG16', 'ResNet-18', 'ResNet-50','ResNet-101']\n",
        "\n",
        "f1_scores = [0.032613168724279835, 0.8310482088966923, 0.06345053429170527,0.929175055247549, 0.9239145583115995,0.920626177590429]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, f1_scores, color='skyblue')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('F1 Scores of Different Models on SVHN Dataset')\n",
        "plt.ylim(0.8, 1.0)\n",
        "plt.xticks(models, rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "ZsFYkcCtFgH7",
        "outputId": "8033208e-2788-47b9-9353-698da0c1291a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}